---
---

<section>
  <div class="container">
    <div class="section-heading reveal">
      <h2>Frequently asked questions</h2>
    </div>

    <div class="faq-list stagger">
      <details class="faq-item">
        <summary>Is my data really private?</summary>
        <div class="faq-body">
          <p>When using local models, yes. High Vibes supports local-first inference:</p>
          <ul>
            <li><strong>Local model execution</strong> — models run on your hardware via Ollama, vLLM, or LM Studio.</li>
            <li><strong>No telemetry during inference</strong> — your prompts and responses stay on your machine when using local agents.</li>
            <li><strong>Local storage</strong> — conversations and settings are stored on your device.</li>
          </ul>
          <p>Premium features like cloud model fallback and remote access do use the network, but only when you explicitly opt in.</p>
          <p><a href={`${import.meta.env.BASE_URL}privacy/`} class="faq-link">Read our full privacy architecture →</a></p>
        </div>
      </details>

      <details class="faq-item">
        <summary>What happens after the trial?</summary>
        <div class="faq-body">
          <p>After your trial expires, you keep full access to local coding agents (Ollama, vLLM, LM Studio) on the free tier. The free tier is ad-supported with a brief interstitial on app open (at most once per hour). Premium features — voice input, remote access, cloud model fallback, and metrics — require a paid subscription.</p>
        </div>
      </details>

      <details class="faq-item">
        <summary>What models can I use?</summary>
        <div class="faq-body">
          <p>Any model supported by Ollama, vLLM, or LM Studio — including Llama 3, Mistral, Phi-3, Gemma, and hundreds more. Premium users can also access cloud models like GPT-4 and Claude as a fallback.</p>
        </div>
      </details>

      <details class="faq-item">
        <summary>What platforms are supported?</summary>
        <div class="faq-body">
          <p>High Vibes runs across three surfaces:</p>
          <ul>
            <li><strong>Desktop service</strong> — a Python-based orchestration service that manages your local coding agents.</li>
            <li><strong>Mobile app</strong> — a React Native app for voice-first interaction with your agents on the go.</li>
            <li><strong>Web dashboard</strong> — view your session history and metrics (no live sessions).</li>
          </ul>
        </div>
      </details>

      <details class="faq-item">
        <summary>What hardware do I need?</summary>
        <div class="faq-body">
          <p>A modern Mac (M1+), Linux, or Windows machine with at least 8GB RAM. Smaller models like Phi-3 run well on modest hardware; larger models benefit from 16GB+ and a discrete GPU.</p>
        </div>
      </details>

      <details class="faq-item">
        <summary>How is this different from ChatGPT/Claude?</summary>
        <div class="faq-body">
          <p>Those are cloud-only services. High Vibes is a local-first interface for coding agents — your code stays on your machine during local inference. It also gives you a mobile app, voice input (Premium), and the flexibility to choose between local and cloud models.</p>
        </div>
      </details>
    </div>
  </div>
</section>

<style>
  .faq-list {
    max-width: 40rem;
    margin-inline: auto;
  }

  .faq-item {
    border-bottom: 1px solid var(--border);
  }

  summary {
    padding: var(--s6) 0;
    font-weight: 600;
    font-size: 1.05rem;
    cursor: pointer;
    list-style: none;
    display: flex;
    justify-content: space-between;
    align-items: center;
  }

  summary::after {
    content: '+';
    font-size: 1.5rem;
    color: var(--text-muted);
    transition: transform 0.2s;
  }

  details[open] summary::after {
    content: '−';
  }

  summary::-webkit-details-marker {
    display: none;
  }

  .faq-body {
    padding-bottom: var(--s6);
    color: var(--text-muted);
    line-height: 1.7;
    font-size: 0.95rem;
  }

  .faq-body ul {
    margin: var(--s3) 0;
    padding-left: var(--s6);
    list-style: disc;
  }

  .faq-body li {
    margin-bottom: var(--s2);
  }

  .faq-link {
    color: var(--coral);
    font-weight: 600;
  }

  .faq-link:hover {
    text-decoration: underline;
  }
</style>
